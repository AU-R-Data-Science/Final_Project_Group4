% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/optim_main.R
\name{conf_matrix}
\alias{conf_matrix}
\title{Create a confusion matrix and output its metrics}
\usage{
conf_matrix(y, X, cutoff = 0.5)
}
\arguments{
\item{y}{A \code{double} value of the vector containing the response of interest.}

\item{X}{An \eqn{n \times p} \code{double} value of the matrix containing the values of the predictors.}

\item{cutoff}{A \code{double} value that sets the probability which determines the predicticted classification of the data set.}
}
\value{
A \code{list} containing the following objects:
\describe{
 \item{Prevalence}{The percentage of positive cases in the data set}
 \item{Accuracy}{The percentage of cases predicted correctly by the model}
 \item{Sensitivity}{The percentage of positive cases predicted correctly by the model}
 \item{Specificity}{The percentage of negative cases predicted correctly by the model}
 \item{False Discovery Rate}{The percentage of cases predicted positive by the model that are actually negative}
 \item{Diagnostic Odds Ratio}{The ratio of the probability of a positive predicted as a negative to the probability of a negative predicted as a negative}
}
}
\description{
This function provides and uses a confusion matrix to assess how closely an optimization technique models the data presented.
}
\author{
Micheal Stewart Jackson
}
